{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2b03d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de tecnicas: 113\n",
      "add: 41\n",
      "remove: 17\n",
      "place: 15\n",
      "serve: 14\n",
      "mix: 12\n",
      "combine: 12\n",
      "cook: 11\n",
      "stir: 11\n",
      "cut: 11\n",
      "bake: 10\n",
      "simmer: 9\n",
      "heat: 9\n",
      "bring: 8\n",
      "chop: 7\n",
      "let: 7\n",
      "saut: 7\n",
      "cover: 7\n",
      "drain: 7\n",
      "refrigerate: 7\n",
      "preheat: 6\n",
      "spread: 6\n",
      "pour: 6\n",
      "toss: 6\n",
      "taste: 5\n",
      "slice: 4\n",
      "make: 4\n",
      "drizzle: 4\n",
      "set aside: 4\n",
      "soak: 4\n",
      "boil: 4\n",
      "set: 4\n",
      "cool: 4\n",
      "transfer: 4\n",
      "sprinkle: 4\n",
      "allow: 3\n",
      "peel: 3\n",
      "reduce: 3\n",
      "garnish: 3\n",
      "fold: 3\n",
      "pulse: 3\n",
      "beat: 3\n",
      "prepare: 3\n",
      "spray: 2\n",
      "roast: 2\n",
      "blend: 2\n",
      "line: 2\n",
      "rinse: 2\n",
      "lay: 2\n",
      "brush: 2\n",
      "spoon: 2\n",
      "open: 2\n",
      "reserve: 2\n",
      "scoop: 2\n",
      "shake: 2\n",
      "puree: 2\n",
      "squeeze: 2\n",
      "score: 2\n",
      "let sit: 2\n",
      "dip: 2\n",
      "whip: 2\n",
      "seed: 1\n",
      "flip: 1\n",
      "turn off and let cool: 1\n",
      "strain and pour: 1\n",
      "get ready: 1\n",
      "have: 1\n",
      "re-heat: 1\n",
      "divide: 1\n",
      "top: 1\n",
      "baste: 1\n",
      "coat: 1\n",
      "tear: 1\n",
      "discard: 1\n",
      "press: 1\n",
      "let set: 1\n",
      "crumble: 1\n",
      "cut up: 1\n",
      "mix in: 1\n",
      "toss in: 1\n",
      "dice: 1\n",
      "core: 1\n",
      "check: 1\n",
      "let cool: 1\n",
      "leave: 1\n",
      "char: 1\n",
      "keep: 1\n",
      "gather: 1\n",
      "warm: 1\n",
      "turn: 1\n",
      "test: 1\n",
      "reduce heat: 1\n",
      "season: 1\n",
      "saute: 1\n",
      "whisk: 1\n",
      "grease: 1\n",
      "invert: 1\n",
      "take: 1\n",
      "start: 1\n",
      "roll: 1\n",
      "store: 1\n",
      "grease and flour: 1\n",
      "add and work: 1\n",
      "add and combine: 1\n",
      "measure and add: 1\n",
      "sift or whisk: 1\n",
      "add and scrape: 1\n",
      "add and mix: 1\n",
      "add and spread: 1\n",
      "transfer and cool: 1\n",
      "remove and lift: 1\n",
      "put: 1\n",
      "remove and let cool: 1\n",
      "pull: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the json in the path \"C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_ingredientes_cultura.json\"\n",
    "with open(r\"C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Otras_Bases\\cbr_dataset_estructurado.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Display the data\n",
    "dict_tecnics = dict()\n",
    "for case in data['menus']:\n",
    "    for key in [\"starter\",\"main\",\"dessert\"]:\n",
    "        for step in case['courses'][key]['structured_instructions']:\n",
    "            action = step.get('preparation_action')\n",
    "            if action:\n",
    "                dict_tecnics[action] = dict_tecnics.get(action, 0) + 1\n",
    "print(\"Numero de tecnicas:\", len(dict_tecnics))\n",
    "# Print all techniques sorted by value\n",
    "for tecnic, count in sorted(dict_tecnics.items(), key=lambda item: item[1], reverse=True):\n",
    "    print(f\"{tecnic}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1edefc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Latin American',\n",
       " 'French/Western European',\n",
       " 'Mediterranean',\n",
       " 'South Asian',\n",
       " 'Chinese',\n",
       " 'American',\n",
       " 'Italian',\n",
       " 'East Asian (General)',\n",
       " 'Japanese',\n",
       " 'Middle Eastern/North African',\n",
       " 'Korean']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_ingredientes_cultura.json\", 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "list_culturas = list(key for key in data[\"ontology_tree\"].keys() if key not in [\"Global/Common\", \"Unspecified\"])\n",
    "list_culturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cdbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "# -------------------------------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------------------------------\n",
    "OUTPUT_JSON = r'C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_cultura_tecnicas.json'\n",
    "OUTPUT_JSON_SUBS = r'C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_tecnica_sustituciones.json'\n",
    "\n",
    "HF_API_KEY = os.environ.get(\"HUGGINGFACE_API_KEY\")\n",
    "HF_MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "HF_CHAT_URL = \"https://router.huggingface.co/v1/chat/completions\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {HF_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "REQUEST_DELAY = 2  # seconds between API calls\n",
    "\n",
    "# -------------------------------------------------\n",
    "# UTILS\n",
    "# -------------------------------------------------\n",
    "def clean_llm_json(text):\n",
    "    \"\"\"Remove markdown and backticks from LLM response\"\"\"\n",
    "    text = re.sub(r\"^```json\", \"\", text.strip(), flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"^```\", \"\", text.strip(), flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"```$\", \"\", text.strip(), flags=re.IGNORECASE)\n",
    "    return text.strip()\n",
    "\n",
    "def parse_llm_response(content):\n",
    "    \"\"\"Convert LLM response to JSON\"\"\"\n",
    "    text = clean_llm_json(content)\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception as e:\n",
    "        return {\"error\": \"json_parse_failed\", \"details\": str(e), \"raw\": text}\n",
    "def remap_json(input_json):\n",
    "    \"\"\"Values become keys, keys become values (list)\"\"\"\n",
    "    output_json = dict()\n",
    "    for key, values in input_json.items():\n",
    "        for value in values:\n",
    "            if value not in output_json:\n",
    "                output_json[value] = []\n",
    "            output_json[value].append(key)\n",
    "    return output_json\n",
    "\n",
    "# -------------------------------------------------\n",
    "# PROMPTS\n",
    "# -------------------------------------------------\n",
    "def create_culture_tecnic_prompt(cultures_list, techniques_list):\n",
    "    \"\"\"Prompt for culture -> representative techniques (with optional extras)\"\"\"\n",
    "    cultures_str = \", \".join(cultures_list)\n",
    "    techniques_str = \", \".join(techniques_list)\n",
    "    prompt = f\"\"\"\n",
    "You are a culinary knowledge expert. Create a comprehensive knowledge base that maps cooking cultures to their representative cooking techniques.\n",
    "\n",
    "Available cultures: {cultures_str}\n",
    "\n",
    "Available techniques: {techniques_str}\n",
    "\n",
    "For each tecnique:\n",
    "- Consider if it is strongly associated with any of the listed cultures. If so, include it in the json with \n",
    "and list of cultures it belongs to, else omit it.\n",
    "- A technique can belong to multiple cultures. At most, list 5 cultures per technique.\n",
    "- Be consistent with culture names as provided in the available cultures list.\n",
    "Rules:\n",
    "- You can add extra techniques not in the available techniques list if they are strongly representative of a culture.\n",
    "- Every culture must have at least 10 techniques associated with it.\n",
    "- Return ONLY a valid JSON object with this structure:\n",
    "{{\n",
    "  \"Tecnique_name\": [\"culture1\", \"culture2\", \"culture3\", ...],\n",
    "  ...\n",
    "}}\n",
    "\n",
    "Do NOT include explanations, markdown, or additional text. Return ONLY the JSON object.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "def create_tecnic_substitution_prompt(techniques_list):\n",
    "    \"\"\"Prompt for technique -> substitute techniques\"\"\"\n",
    "    techniques_str = \", \".join(techniques_list)\n",
    "    prompt = f\"\"\"\n",
    "You are a culinary expert. For each cooking technique, propose close substitutes from the provided list.\n",
    "\n",
    "Available techniques: {techniques_str}\n",
    "\n",
    "Rules:\n",
    "- For each technique, return 3-6 alternative techniques that could replace it in a recipe.\n",
    "- Use only techniques from the available list (no new ones).\n",
    "- Do NOT include the original technique in its own substitution list.\n",
    "- Favor substitutions that preserve texture/result as much as possible.\n",
    "\n",
    "Return ONLY a valid JSON object with this structure:\n",
    "{{\n",
    "  \"technique\": [\"substitute1\", \"substitute2\", ...],\n",
    "  ...\n",
    "}}\n",
    "\n",
    "Do NOT include explanations, markdown, or additional text. Return ONLY the JSON object.\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# -------------------------------------------------\n",
    "# LLM CALL\n",
    "# -------------------------------------------------\n",
    "def generate_knowledge_base(prompt, output_path, max_retries=3):\n",
    "    \"\"\"\n",
    "    Generic LLM call with retries and JSON save.\n",
    "    \"\"\"\n",
    "    if not HF_API_KEY:\n",
    "        return {\"error\": \"HUGGINGFACE_API_KEY not set\"}\n",
    "\n",
    "    payload = {\n",
    "        \"model\": HF_MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_new_tokens\": 2000\n",
    "    }\n",
    "\n",
    "    # Retry logic with exponential backoff\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  ðŸ“¡ Calling LLM (attempt {attempt + 1}/{max_retries})...\", end=\"\", flush=True)\n",
    "            response = requests.post(HF_CHAT_URL, headers=HEADERS, json=payload, timeout=120)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                print(\" âœ“\")\n",
    "                result = response.json()\n",
    "                content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "                kb = parse_llm_response(content)\n",
    "                kb = remap_json(kb)\n",
    "                \n",
    "                # Save to JSON\n",
    "                print(f\"  ðŸ’¾ Saving to {output_path}\")\n",
    "                os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "                with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                    json.dump(kb, f, ensure_ascii=False, indent=2)\n",
    "                \n",
    "                print(f\"  âœ… Saved successfully\")\n",
    "                return kb\n",
    "                \n",
    "            elif response.status_code in [502, 503, 504]:\n",
    "                # Server errors - retry with backoff\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    print(f\" âš ï¸  HTTP {response.status_code}, retrying in {wait_time}s...\")\n",
    "                    sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\" âœ—\")\n",
    "                    return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text[:500]}\n",
    "            else:\n",
    "                # Other errors\n",
    "                print(f\" âœ—\")\n",
    "                return {\"error\": f\"HTTP {response.status_code}\", \"details\": response.text[:500]}\n",
    "                \n",
    "        except requests.Timeout:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                print(f\" âš ï¸  Timeout, retrying in {wait_time}s...\")\n",
    "                sleep(wait_time)\n",
    "            else:\n",
    "                print(f\" âœ—\")\n",
    "                return {\"error\": \"llm_call_failed\", \"details\": \"Request timeout after all retries\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                print(f\" âš ï¸  Error ({str(e)[:50]}), retrying in {wait_time}s...\")\n",
    "                sleep(wait_time)\n",
    "            else:\n",
    "                print(f\" âœ—\")\n",
    "                return {\"error\": \"llm_call_failed\", \"details\": str(e)[:500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c52c8246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Creating culture-technique KB with 11 cultures and 113 techniques...\n",
      "  ðŸ“¡ Calling LLM (attempt 1/3)... âœ“\n",
      "  ðŸ’¾ Saving to C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_cultura_tecnicas.json\n",
      "  âœ… Saved successfully\n",
      "\n",
      "âœ… Culture-technique KB saved: C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_cultura_tecnicas.json\n",
      "ðŸ” Creating technique-substitution KB for 112 techniques...\n",
      "  ðŸ“¡ Calling LLM (attempt 1/3)... âœ“\n",
      "  ðŸ’¾ Saving to C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_tecnica_sustituciones.json\n",
      "  âœ… Saved successfully\n",
      "\n",
      "âœ… Technique-substitution KB saved: C:\\Users\\jiaha\\Documents\\Universidad\\SBC\\SBC-MENU\\PART2\\Bases_Conocimientos\\ontologia_tecnica_sustituciones.json\n",
      "   Total techniques with substitutes: 93\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if HF_API_KEY:\n",
    "    # Get cultures from the ontology\n",
    "    culturas_lista = list_culturas\n",
    "    \n",
    "    # Get techniques from the first cell\n",
    "    tecnicas_lista = sorted(dict_tecnics.keys())\n",
    "    \n",
    "    print(f\"ðŸ”¬ Creating culture-technique KB with {len(culturas_lista)} cultures and {len(tecnicas_lista)} techniques...\")\n",
    "    prompt_cult = create_culture_tecnic_prompt(culturas_lista, tecnicas_lista)\n",
    "    kb_cult = generate_knowledge_base(prompt_cult, OUTPUT_JSON)\n",
    "\n",
    "    if \"error\" not in kb_cult:\n",
    "        print(f\"\\nâœ… Culture-technique KB saved: {OUTPUT_JSON}\")\n",
    "        # Build technique set from the generated KB (deduplicated)\n",
    "        all_tecnicas_from_kb = sorted({tech for techs in kb_cult.values() for tech in techs if isinstance(techs, list)})\n",
    "        print(f\"ðŸ” Creating technique-substitution KB for {len(all_tecnicas_from_kb)} techniques...\")\n",
    "        prompt_subs = create_tecnic_substitution_prompt(all_tecnicas_from_kb)\n",
    "        kb_subs = generate_knowledge_base(prompt_subs, OUTPUT_JSON_SUBS)\n",
    "\n",
    "        if \"error\" not in kb_subs:\n",
    "            print(f\"\\nâœ… Technique-substitution KB saved: {OUTPUT_JSON_SUBS}\")\n",
    "            print(f\"   Total techniques with substitutes: {len(kb_subs)}\")\n",
    "        else:\n",
    "            print(f\"âŒ Error generating substitutions: {kb_subs}\")\n",
    "    else:\n",
    "        print(f\"âŒ Error generating culture-technique KB: {kb_cult}\")\n",
    "else:\n",
    "    print(\"âŒ HUGGINGFACE_API_KEY not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json in the path OuTPUT_JSON_SUBS and OUTPUT_JSON and display them\n",
    "with open(OUTPUT_JSON_SUBS, 'r', encoding='utf-8') as f:\n",
    "    x = json.load(f)\n",
    "data_sub = dict()\n",
    "for key, value in x.items():\n",
    "    data_sub[key] = set(value)\n",
    "with open(OUTPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "    x = json.load(f)\n",
    "data_cult = dict()\n",
    "for key, value in x.items():\n",
    "    data_cult[key] = set(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8f655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latin American</th>\n",
       "      <th>Mediterranean</th>\n",
       "      <th>South Asian</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Italian</th>\n",
       "      <th>French/Western European</th>\n",
       "      <th>Middle Eastern/North African</th>\n",
       "      <th>East Asian</th>\n",
       "      <th>Japanese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Latin American</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mediterranean</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Asian</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French/Western European</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle Eastern/North African</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East Asian</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japanese</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Latin American  Mediterranean  South Asian  \\\n",
       "Latin American                             0              0            0   \n",
       "Mediterranean                             82              0           82   \n",
       "South Asian                                0              0            0   \n",
       "Chinese                                    0              0            0   \n",
       "Italian                                    4              0            4   \n",
       "French/Western European                   82              0           82   \n",
       "Middle Eastern/North African              78              0           78   \n",
       "East Asian                                82              0           82   \n",
       "Japanese                                  82              0           82   \n",
       "\n",
       "                              Chinese  Italian  French/Western European  \\\n",
       "Latin American                      0        0                       30   \n",
       "Mediterranean                      82       78                       30   \n",
       "South Asian                         0        0                       30   \n",
       "Chinese                             0        0                       30   \n",
       "Italian                             4        0                       30   \n",
       "French/Western European            82       78                        0   \n",
       "Middle Eastern/North African       78       78                        0   \n",
       "East Asian                         82       78                        0   \n",
       "Japanese                           82       78                        0   \n",
       "\n",
       "                              Middle Eastern/North African  East Asian  \\\n",
       "Latin American                                          30          30   \n",
       "Mediterranean                                           34          30   \n",
       "South Asian                                             30          30   \n",
       "Chinese                                                 30          30   \n",
       "Italian                                                 34          30   \n",
       "French/Western European                                  4           0   \n",
       "Middle Eastern/North African                             0           0   \n",
       "East Asian                                               4           0   \n",
       "Japanese                                                 4           0   \n",
       "\n",
       "                              Japanese  \n",
       "Latin American                      30  \n",
       "Mediterranean                       30  \n",
       "South Asian                         30  \n",
       "Chinese                             30  \n",
       "Italian                             30  \n",
       "French/Western European              0  \n",
       "Middle Eastern/North African         0  \n",
       "East Asian                           0  \n",
       "Japanese                             0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quiero crear una matriz de distancia entre culturas basado en las tecnicas de cocina que tiene uno pero no el otro.\n",
    "culturas = list(data_cult.keys())\n",
    "import numpy as np\n",
    "dist_matrix = np.zeros((len(culturas), len(culturas)), dtype=int)\n",
    "for i in range(len(culturas)):\n",
    "    for j in range(i+1, len(culturas)):\n",
    "        cult1 = culturas[i]\n",
    "        cult2 = culturas[j]\n",
    "        tecnicas_cult1 = data_cult[cult1]\n",
    "        tecnicas_cult2 = data_cult[cult2]\n",
    "        \"\"\"common_tecnicas = tecnicas_cult1.intersection(tecnicas_cult2)\n",
    "        if len(common_tecnicas) == min(len(tecnicas_cult1), len(tecnicas_cult2)):\n",
    "            dist_matrix[i, j] = -1\n",
    "            dist_matrix[j, i] = -1\n",
    "            continue\"\"\"\n",
    "        # Calcular la distancia como el numero de tecnicas que tiene cult1 pero no cult2\n",
    "        dist = len(tecnicas_cult1 - tecnicas_cult2)\n",
    "        dist_matrix[i, j] = dist\n",
    "        # Callculamos el numero de tecnicas que tiene cult2 pero no cult1\n",
    "        dist = len(tecnicas_cult2 - tecnicas_cult1)\n",
    "        dist_matrix[j, i] = dist\n",
    "\n",
    "# Display the distance matrix\n",
    "import pandas as pd \n",
    "df_dist = pd.DataFrame(dist_matrix, index=culturas, columns=culturas)\n",
    "df_dist\n",
    "# Result explanation: The distance matrix shows the number of unique cooking techniques that one culture has compared to another. \n",
    "# A value of -1 indicates that one culture's techniques are a subset of the other's.\n",
    "# For example, if df_dist.loc['Italian', 'French'] = 5, it means Italian cuisine has 5 cooking techniques that French cuisine does not have.\n",
    "# And df_dist.loc['French', 'Italian'] = 3 means French cuisine has 3 cooking techniques that Italian cuisine does not have.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c541aee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin American: 30 techniques\n",
      "Mediterranean: 112 techniques\n",
      "South Asian: 30 techniques\n",
      "Chinese: 30 techniques\n",
      "Italian: 34 techniques\n",
      "French/Western European: 82 techniques\n",
      "Middle Eastern/North African: 78 techniques\n",
      "East Asian: 82 techniques\n",
      "Japanese: 82 techniques\n"
     ]
    }
   ],
   "source": [
    "for key, value in data_cult.items():\n",
    "    print(f\"{key}: {len(value)} techniques\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
